---
layout: post
title:  ç®€å•è°ƒæ•™äº†ä¸‹DeepSeek
categories: [cs, physics]
tags: [life, cs]
---
ä»Šå¤©æ˜¯å’ŒDeepSeekæ–—æ™ºæ–—å‹‡çš„ä¸€æ•´å¤©ï¼Œåˆ«çœ‹æˆ‘å»ºäº†è¿™ä¸€æ•´ä¸ªç½‘ç«™ï¼Œå…¶å®å¯¹å‰ç«¯ä¸€çªä¸é€šï¼Œä½†DeepSeekå´èƒ½å¸®æˆ‘å†™å‡ºè¿™ä¹ˆå¤šè¿˜çœ‹å¾—è¿‡å»çš„csså’ŒåŠŸèƒ½è¿˜å‡‘æ´»çš„jsã€‚æ™šä¸Šzoteroçªå‘æ¶ç–¾ï¼ŒåŸæ¥çš„arxivè®¢é˜…ä¸çŸ¥é“å’‹å›äº‹æ— æ³•åŠæ—¶æ›´æ–°ï¼Œæœ¬æ¥è®¢é˜…äº†æ¯å¤©çš„arxivé‚®ä»¶ï¼Œä¸è¿‡æ’ç‰ˆå®åœ¨æ˜¯ä¸€è¨€éš¾å°½ï¼Œæ‰€ä»¥å°±ç¢ç£¨ç€èƒ½ä¸èƒ½ç”¨pythonå†™ä¸€ä¸ªè‡ªåŠ¨çˆ¬å–arxivçš„å°ç¨‹åºï¼Œä¸è¿‡æœ‰äº†deepseekç¡®å®å‘ç°è‡ªå·±ä»£ç æ°´å¹³å·²ç»ä¸‹é™åˆ°å°å­¦ç”Ÿä¿¡æ¯è¯¾æ°´å¹³ã€‚ã€‚ã€‚
<!--more-->

è°ƒæ•™äº†å¤§æ¦‚ä¸¤ä¸‰ä¸ªå°æ—¶çš„DeepSeekï¼Œç°åœ¨åŠŸèƒ½åŸºæœ¬é½å…¨äº†ï¼Œåœ¨å·¥ä½œæ—¥ä¼šè‡ªåŠ¨çˆ¬å–å‰24å°æ—¶æŠ•é€’çš„æ–‡çŒ®ï¼Œåœ¨åŒä¼‘æ—¥åˆ™ä¼šè‡ªåŠ¨çˆ¬å–ä¸€æ•´å‘¨çš„æ–‡çŒ®ï¼Œè€Œä¸”æ’ç‰ˆæ”¹çš„æˆ‘è¿˜æ»¡æ„ã€‚æ¯”è¾ƒå¥½çš„åŠŸèƒ½æ˜¯å¯ä»¥è‡ªåŠ¨æŸ¥æ‰¾ä½œè€…çš„inspireä¸»é¡µï¼Œè¿™æ ·å°±èƒ½ä¸€é”®çœ‹çœ‹æ˜¯ä¸æ˜¯å¤§ä½¬å†™çš„æ–‡ç« ã€‚ã€‚ã€‚

å…¶å®è¿™éƒ½æ˜¯éå¸¸ç®€å•çš„ä»£ç ï¼Œæ²¡æœ‰ä»€ä¹ˆå¤æ‚çš„é€»è¾‘åœ¨é‡Œé¢ï¼Œdeepseekå¤„ç†èµ·æ¥è½»è½»æ¾æ¾ï¼Œä¸€æ—¦æ¶‰åŠåˆ°ä¸€äº›å›°éš¾çš„ï¼Œç‰¹åˆ«æ˜¯é‡Œé¢æœ‰å¾ˆå¤æ‚çš„é€»è¾‘çš„æ—¶å€™deepseekå°±ä¸ä¼šå¤„ç†äº†ï¼Œæ¯”å¦‚è¿™ä¸ªtime_periodéœ€è¦æ ¹æ®[arxivå®˜æ–¹å‘å¸ƒçš„æ—¶åˆ»è¡¨](https://info.arxiv.org/help/availability.html)æ¥æ¨æ–­éœ€è¦è·å–ä»€ä¹ˆæ—¶é—´æ®µçš„æ–‡çŒ®ï¼Œå°±è¿™ä¸ªäººç±»å¾ˆå®¹æ˜“ç†è§£çš„é€»è¾‘deepseekéœ€è¦æˆ‘çº æ­£å¤šæ¬¡æ‰èƒ½å¼„æ‡‚ï¼ˆå¯èƒ½ä¹Ÿæ˜¯æˆ‘é—®çš„ä¸å¥½ï¼‰ã€‚

ä»£ç å¦‚ä¸‹ï¼Œå¦‚æœåé¢ä½¿ç”¨æœ‰ä»€ä¹ˆbugæˆ‘å†æ”¹åŠ¨ï¼š

# æºä»£ç 

## main.py

```python
import requests
import feedparser
from datetime import datetime, timedelta, timezone
import re
from arxiv_cats import get_all_arxiv_categories, primary_categories
from crawler import get_inspire_paper_info, get_inspire_author_link
from time_period import get_arxiv_submission_period

# ç”¨æˆ·é€‰æ‹©åˆ†åŒº
def select_arxiv_category():
    """è®©ç”¨æˆ·é€‰æ‹©arXivåˆ†åŒºï¼Œé»˜è®¤è¿”å›hep-th"""
    valid_categories = get_all_arxiv_categories()
    
    while True:
        user_input = input("ğŸ“š è¯·è¾“å…¥ä½ æƒ³æŸ¥çœ‹çš„arXivåˆ†åŒº (ç›´æ¥å›è½¦é»˜è®¤ä¸º hep-th): ").strip()
        
        # é»˜è®¤å€¼
        if user_input == "":
            return "hep-th"
        
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰æ•ˆ
        if user_input in valid_categories:
            return user_input
        
        print(f"âš ï¸ é”™è¯¯: '{user_input}' ä¸æ˜¯æœ‰æ•ˆçš„ï¼ˆäºŒçº§ï¼‰arXivåˆ†åŒºã€‚")
        print("è¯·ä½¿ç”¨ä»¥ä¸‹ï¼ˆä¸€çº§ï¼‰åˆ†åŒºå¯¹åº”çš„å­åˆ†åŒº: " + ", ".join(primary_categories()))
        print("è¯·é‡æ–°è¾“å…¥æˆ–ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ã€‚\n")

def main(category=None, start_date=None, end_date = datetime.now(timezone.utc)):
    if not category:
        # è®©ç”¨æˆ·é€‰æ‹©arXivåˆ†åŒº
        category = select_arxiv_category()
        print(f"\nğŸ”¬ ä½ é€‰æ‹©çš„åˆ†åŒºæ˜¯: {category}\n")
    
    # è·å–å½“å‰UTCæ—¶é—´
    now = datetime.now(timezone.utc)

    if not start_date:
        # è·å–arXivæäº¤æ—¶é—´æ®µ
        start_date, end_date, time_range_description, is_weekend = get_arxiv_submission_period()
    else:
        is_weekend= False
        time_range_description = f"ğŸ¤” è‡ªå®šä¹‰èŒƒå›´æ¨¡å¼ï¼šæŸ¥æ‰¾äº†è¿‡å»{end_date.__sub__(start_date)}å¤©çš„è®ºæ–‡"

    # è½¬æ¢ä¸ºUTCæ—¶é—´
    start_date_utc = start_date.astimezone(timezone.utc)
    end_date_utc = end_date.astimezone(timezone.utc)

    # æ ¼å¼åŒ–ä¸ºarXiv APIéœ€è¦çš„æ ¼å¼ï¼ˆYYYYMMDDHHMMï¼‰
    start_date = start_date_utc.strftime('%Y%m%d%H%M')
    end_date = end_date_utc.strftime('%Y%m%d%H%M')
    
    # æ„é€ APIæŸ¥è¯¢URL
    query = f'submittedDate:[{start_date} TO {end_date}] AND cat:{category}'
    base_url = 'http://export.arxiv.org/api/query?'
    params = {
        'search_query': query,
        'sortBy': 'submittedDate',
        'sortOrder': 'descending',
        'max_results': 500,  # å¢åŠ æ•°é‡ä»¥å®¹çº³ä¸€å‘¨çš„è®ºæ–‡
        'start': 0
    }

    print(f"â³ æŸ¥è¯¢arXiv API: {query}")
    print(f"  æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
    print(f"  æ¨¡å¼: {time_range_description}")

    # å‘é€APIè¯·æ±‚
    response = requests.get(base_url, params=params)

    # è§£æAtomå“åº”
    feed = feedparser.parse(response.content)
    num_papers = len(feed.entries)
    
    # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è®ºæ–‡
    if num_papers == 0:
        print("\n" + "="*60)
        print("ğŸŒŸ ä»Šå¤©æ²¡æœ‰æ–°è®ºæ–‡ï¼ ğŸŒŸ")
        print("="*60)
        print(f"\nğŸ” åœ¨ {category} åˆ†åŒºä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–°è®ºæ–‡ã€‚")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date[:4]}.{start_date[4:6]}.{start_date[6:8]} åˆ° {end_date[:4]}.{end_date[4:6]}.{end_date[6:8]}")
        print(f"â° ä¸‹æ¬¡æ›´æ–°æ—¶é—´: æ˜å¤©åŒä¸€æ—¶é—´å†æ¥çœ‹çœ‹å§ï¼")
        print(f"ğŸ’¡ æç¤º: å¯ä»¥å°è¯•é€‰æ‹©å…¶ä»–åˆ†åŒºæˆ–æ‰©å¤§æ—¶é—´èŒƒå›´")
        if input(f"ğŸ§ æƒ³çœ‹çœ‹æ›´æ—©çš„è®ºæ–‡å—ï¼Ÿ(Y/N): ").strip().lower() == "y":
            new_timedelta = int(input(f"ğŸ“… æƒ³çœ‹å¤šä¹…ä¹‹å‰çš„å‘¢: "))
            main(category, start_date=(now - timedelta(days=new_timedelta)))
        return  # ç›´æ¥é€€å‡ºï¼Œä¸æ‰§è¡Œåç»­æ“ä½œ

    print(f"âœ… æ‰¾åˆ° {num_papers} ç¯‡è®ºæ–‡")

    # å­˜å‚¨ä¸»åˆ†åŒºä¸ºé€‰å®šåˆ†åŒºå’Œå…¶ä»–åˆ†åŒºçš„è®ºæ–‡
    primary_papers = []
    other_papers = []

    # è¿›åº¦è®¡æ•°å™¨
    processed = 0

    for entry in feed.entries:
        processed += 1
        # æå–arXiv ID
        arxiv_id = entry.id.split('/')[-1]
        # ç§»é™¤ç‰ˆæœ¬å·ï¼ˆå¦‚v1, v2ç­‰ï¼‰
        arxiv_id_clean = re.sub(r'v\d+$', '', arxiv_id)
        
        # æ¸…ç†æ ‡é¢˜å¹¶è½¬æ¢å…¬å¼æ ‡è®°
        title = entry.title.replace('\n', ' ').strip()
        # æŠŠå¤šä¸ªç©ºæ ¼è½¬æ¢ä¸ºå•ä¸ªç©ºæ ¼
        title = " ".join(title.split())
        # å°† \(...\) è½¬æ¢ä¸º $...$
        title = re.sub(r'\\\((.*?)\\\)', r'$\1$', title)
        # å°† \[...\] è½¬æ¢ä¸º $$...$$
        title = re.sub(r'\\\[(.*?)\\\]', r'$$\1$$', title)
        
        print(f"\nğŸ“„ [{processed}/{num_papers}] å¤„ç†è®ºæ–‡: {title[:60]}...")
        
        # è·å–æ–‡ç« çš„åˆ†ç±»ä¿¡æ¯
        categories = [tag['term'] for tag in entry.tags]
        primary_category = categories[0] if categories else "unknown"
        
        if category in ['hep-th','hep-ph','hep-ex','hep-lat','math-ph','gr-qc']:
            # é¦–å…ˆå°è¯•é€šè¿‡arXiv IDè·å–INSPIREä¸Šçš„ä½œè€…ä¿¡æ¯
            inspire_authors = get_inspire_paper_info(arxiv_id_clean)
            
            if inspire_authors:
                print(f"   âœ… ä½¿ç”¨INSPIREä¸Šçš„ä½œè€…åˆ—è¡¨")
                # ä½¿ç”¨INSPIREä¸Šçš„ä½œè€…ä¿¡æ¯
                author_links = []
                for author in inspire_authors:
                    if author['link']:
                        author_links.append(f"[{author['name']}]({author['link']})")
                    else:
                        author_links.append(author['name'])
                
                authors = ', '.join(author_links)
            else:
                # ä¸åœ¨inspireä¸Šçš„æ–‡çŒ®æ ‡è®°ä¸€ä¸‹ï¼Œä»è€Œä½œè€…ç´¢å¼•å¯èƒ½ä¸å‡†ç¡®
                title = "[**âš ï¸ Not in INSPIRE âš ï¸**] "+title
                print(f"   âš ï¸ æœªæ‰¾åˆ°INSPIREè®°å½•ï¼Œä½¿ç”¨arXivä½œè€…åˆ—è¡¨")
                # ä½¿ç”¨arXivä½œè€…åˆ—è¡¨å¹¶è¿›è¡Œé€ä¸ªåŒ¹é…
                author_links = []
                for author in entry.authors:
                    author_name = author.name
                    print(f"  ğŸ‘¤ ä½œè€…: {author_name}")
                    
                    # è·å–INSPIREä¸Šçš„ä½œè€…ä¿¡æ¯
                    inspire_name, inspire_link = get_inspire_author_link(author_name)
                    
                    # ä½¿ç”¨INSPIREä¸Šçš„ä½œè€…åå’Œé“¾æ¥ï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
                    if inspire_link:
                        author_links.append(f"[{inspire_name}]({inspire_link})")
                    else:
                        # æ²¡æœ‰æ‰¾åˆ°é“¾æ¥ï¼Œä½¿ç”¨åŸå§‹åå­—
                        author_links.append(author_name)
                
                authors = ', '.join(author_links)
        else:
            # éé«˜èƒ½æ–¹å‘ä¸ä½¿ç”¨INSPIRE
            author_links = []
            for author in entry.authors:
                author_name = author.name
                author_links.append(author_name)
            authors = ', '.join(author_links)
        
        # æ¸…ç†æ‘˜è¦å¹¶è½¬æ¢å…¬å¼æ ‡è®°
        abstract = entry.summary.replace('\n', ' ').strip()
        # å°† \(...\) è½¬æ¢ä¸º $...$
        abstract = re.sub(r'\\\((.*?)\\\)', r'$\1$', abstract)
        # å°† \[...\] è½¬æ¢ä¸º $$...$$
        abstract = re.sub(r'\\\[(.*?)\\\]', r'$$\1$$', abstract)
        
        # è·å–æäº¤æ—¥æœŸ
        published = datetime.strptime(entry.published, '%Y-%m-%dT%H:%M:%SZ')
        
        # æ„å»ºè®ºæ–‡ä¿¡æ¯å­—å…¸
        paper_info = {
            'title': title,
            'authors': authors,
            'abstract': abstract,
            'published': published,
            'arxiv_id_clean': arxiv_id_clean,
            'primary_category': primary_category,
            'all_categories': categories
        }
        
        # æ ¹æ®ä¸»åˆ†ç±»å°†è®ºæ–‡åˆ†ç»„
        if primary_category == category:
            primary_papers.append(paper_info)
        else:
            other_papers.append(paper_info)

    # ç”ŸæˆMarkdownå†…å®¹
    markdown_content = f"# arXiv {category} Papers ({time_range_description})\n\n"
    markdown_content += f"*Generated at: {now.strftime('%Y-%m-%d %H:%M:%S UTC')}*\n"
    markdown_content += f"*Date Range: {start_date[:4]}.{start_date[4:6]}.{start_date[6:8]} to {end_date[:4]}.{end_date[4:6]}.{end_date[6:8]}*\n\n"
    markdown_content += f"## Found {len(primary_papers)} papers (primary in {category}) and {len(other_papers)} related papers\n\n"
    markdown_content += "---\n"

    # ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»åˆ†åŒºä¸ºé€‰å®šåˆ†åŒºçš„è®ºæ–‡
    if primary_papers:
        markdown_content += f"## Primary in {category} ({len(primary_papers)} papers)\n\n"
        
        for paper in primary_papers:
            # æ ¼å¼åŒ–åˆ†ç±»ä¿¡æ¯
            primary_str = f"**`{paper['primary_category']}`**"
            # è·å–å…¶ä»–åˆ†ç±»ï¼ˆå»é‡å¹¶æ’é™¤ä¸»åˆ†ç±»ï¼‰
            other_categories = list(set(paper['all_categories']) - {paper['primary_category']})
            other_categories_str = ', '.join([f"`{cat}`" for cat in other_categories])
            
            category_info = primary_str
            if other_categories_str:
                category_info += f", {other_categories_str}"
            
            markdown_content += f"### [{paper['title']}](https://arxiv.org/abs/{paper['arxiv_id_clean']})\n"
            markdown_content += f"{paper['authors']}\n"  # ä¸¤ä¸ªç©ºæ ¼å¼ºåˆ¶æ¢è¡Œ
            markdown_content += f"{category_info}\n"
            markdown_content += f"*Submitted: {paper['published'].strftime('%Y-%m-%d %H:%M UTC')}*\n\n"
            markdown_content += f"> {paper['abstract']}\n\n"  # æ‘˜è¦æ”¾åœ¨å¼•ç”¨å—ä¸­
            markdown_content += "---\n"

    # ç¬¬äºŒéƒ¨åˆ†ï¼šä¸»åˆ†åŒºä¸æ˜¯é€‰å®šåˆ†åŒºçš„ç›¸å…³è®ºæ–‡
    if other_papers:
        markdown_content += f"## Related Papers in Other Categories ({len(other_papers)} papers)\n\n"
        markdown_content += f"*Note: These papers are listed in {category} but have a primary category in another field*\n\n"
        
        for paper in other_papers:
            # æ ¼å¼åŒ–åˆ†ç±»ä¿¡æ¯
            primary_str = f"**`{paper['primary_category']}`**"
            # è·å–å…¶ä»–åˆ†ç±»ï¼ˆå»é‡å¹¶æ’é™¤ä¸»åˆ†ç±»ï¼‰
            other_categories = list(set(paper['all_categories']) - {paper['primary_category']})
            other_categories_str = ', '.join([f"`{cat}`" for cat in other_categories])
            
            category_info = primary_str
            if other_categories_str:
                category_info += f", {other_categories_str}"
            
            markdown_content += f"### [{paper['title']}](https://arxiv.org/abs/{paper['arxiv_id_clean']})\n"
            markdown_content += f"{paper['authors']}\n"  # ä¸¤ä¸ªç©ºæ ¼å¼ºåˆ¶æ¢è¡Œ
            markdown_content += f"{category_info}\n"
            markdown_content += f"*Submitted: {paper['published'].strftime('%Y-%m-%d %H:%M UTC')}*\n\n"
            markdown_content += f"> {paper['abstract']}\n\n"  # æ‘˜è¦æ”¾åœ¨å¼•ç”¨å—ä¸­
            markdown_content += "---\n"

    # å†™å…¥Markdownæ–‡ä»¶
    filename = f"{category}_papers_{now.strftime('%Y%m%d_%H%M%S')}.md"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(markdown_content)

    print(f"\nâœ… æˆåŠŸä¿å­˜ {len(primary_papers)} ç¯‡ä¸»åˆ†åŒº{category}è®ºæ–‡å’Œ {len(other_papers)} ç¯‡ç›¸å…³è®ºæ–‡åˆ° {filename}")
    if is_weekend:
        print("ï¸ğŸ–ï¸ å‘¨æœ«äº†ï¼Œè®©æˆ‘ä»¬å›é¡¾ä»¥ä¸‹è¿™å‘¨å­¦æœ¯ç•Œå‘ç”Ÿäº†ä»€ä¹ˆ")
    else:
        print("ğŸ¢ å·¥ä½œæ—¥ï¼Œçœ‹çœ‹æ˜¨å¤©å¤§å®¶æ•´äº†ä»€ä¹ˆæ´»")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {time_range_description} (ç¾å›½ä¸œéƒ¨æ—¶é—´)")
    print("â„¹ï¸ ä½œè€…ä¿¡æ¯ä¼˜å…ˆä½¿ç”¨INSPIREä¸Šçš„è®°å½•")
    print("â„¹ï¸ å…¬å¼æ ‡è®°å·²è½¬æ¢ä¸ºMarkdownå…¼å®¹æ ¼å¼")
    print(f"â„¹ï¸ è®ºæ–‡æŒ‰ä¸»åˆ†ç±»åˆ†ç»„: {category}ä¸»åˆ†åŒºåœ¨å‰ï¼Œå…¶ä»–ç›¸å…³è®ºæ–‡åœ¨å")

if __name__ == "__main__":
    flag = 1
    while flag:
        main()
        continue_flag = input("ğŸ§ è¿˜è¦ç»§ç»­çœ‹å— (Y/N) : ").strip().lower()
        if continue_flag == "n":
            flag = 0
```

## crawler

è¿™ä¸ªæ˜¯çˆ¬è™«ä¸»è¦åœ¨çš„ç¨‹åº
```python
from urllib.parse import quote
import requests
import time
import re
import unidecode
import difflib

def normalize_name(name):
    """æ ‡å‡†åŒ–ä½œè€…åå­—ä»¥è¿›è¡Œæ›´å¥½çš„æ¯”è¾ƒ"""
    # ç§»é™¤é‡éŸ³ç¬¦å·
    name = unidecode.unidecode(name)
    # è½¬æ¢ä¸ºå°å†™
    name = name.lower()
    # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹
    name = re.sub(r'[^\w\s]', '', name)
    # ä¿ç•™å§“æ°å’Œåå­—çš„é¦–å­—æ¯ï¼ˆå¤„ç†ä¸­é—´åå·®å¼‚ï¼‰
    parts = name.split()
    if len(parts) > 1:
        # ä¿ç•™å§“æ°å…¨åå’Œåå­—é¦–å­—æ¯
        last_name = parts[-1]
        first_initials = "".join([p[0] for p in parts[:-1]])
        return f"{first_initials}{last_name}"
    return name

def get_inspire_paper_info(arxiv_id):
    """é€šè¿‡arXiv IDè·å–INSPIREä¸Šçš„è®ºæ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½œè€…åˆ—è¡¨"""
    inspire_url = f"https://inspirehep.net/api/literature?q=arxiv:{arxiv_id}"
    try:
        print(f"ğŸ” é€šè¿‡æ–‡ç« å· {arxiv_id} æŸ¥æ‰¾INSPIREè®°å½•...")
        response = requests.get(inspire_url, headers={"Accept": "application/json"})

        if response.status_code == 200:
            data = response.json()
            total_hits = data.get('hits', {}).get('total', 0)

            if total_hits > 0:
                print(f"   âœ… æ‰¾åˆ°æ–‡ç« è®°å½• ({total_hits} æ¡åŒ¹é…)")
                # è·å–ç¬¬ä¸€ç¯‡æ–‡ç« è®°å½•ä¸­çš„æ‰€æœ‰ä½œè€…
                authors = data['hits']['hits'][0]['metadata'].get('authors', [])
                print(f"   æ–‡ç« ä¸­æœ‰ {len(authors)} ä½ä½œè€…è®°å½•")

                # æå–ä½œè€…ä¿¡æ¯
                author_info = []
                for author in authors:
                    full_name = author.get('full_name', '')
                    recid = author.get('recid')

                    # è½¬æ¢åå­—æ ¼å¼ï¼šä»"å§“, å"æ”¹ä¸º"å å§“"
                    if ',' in full_name:
                        last_name, first_name = full_name.split(',', 1)
                        formatted_name = f"{first_name.strip()} {last_name.strip()}"
                    else:
                        formatted_name = full_name

                    if formatted_name and recid:
                        author_info.append({
                            'name': formatted_name,
                            'link': f"https://inspirehep.net/authors/{recid}"
                        })
                    elif formatted_name:
                        author_info.append({
                            'name': formatted_name,
                            'link': None
                        })
                    else:
                        author_info.append({
                            'name': "Unknown",
                            'link': None
                        })
                return author_info
            else:
                print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ–‡ç«  {arxiv_id} çš„INSPIREè®°å½•")
        else:
            print(f"   âŒ INSPIRE API é”™è¯¯: HTTP {response.status_code}")
    except Exception as e:
        print(f"   âŒ é€šè¿‡æ–‡ç« å·æŸ¥æ‰¾æ—¶å‡ºé”™: {str(e)}")

    # æ·»åŠ å»¶è¿Ÿä»¥é¿å…é¢‘ç¹è¯·æ±‚INSPIRE API
    time.sleep(0.3)

    return None


def get_inspire_author_link(author_name):
    """é€šè¿‡ä½œè€…åæœç´¢INSPIREé“¾æ¥ï¼ˆå½“æ•´ç¯‡æ–‡ç« æœªåŒ¹é…æ—¶ä½¿ç”¨ï¼‰"""
    # æ ‡å‡†åŒ–æŸ¥è¯¢åç§°
    normalized_query = normalize_name(author_name)

    search_name = quote(author_name)
    inspire_url = f"https://inspirehep.net/api/authors?q={search_name}&size=5"  # è·å–å‰5ä¸ªç»“æœ
    try:
        print(f"ğŸ” é€šè¿‡ä½œè€…åæœç´¢: {author_name}...")
        response = requests.get(inspire_url, headers={"Accept": "application/json"})

        if response.status_code == 200:
            data = response.json()
            total_hits = data.get('hits', {}).get('total', 0)

            if total_hits > 0:
                print(f"   âœ… æ‰¾åˆ° {total_hits} ä¸ªåŒ¹é…çš„ä½œè€…")

                # åˆ›å»ºå€™é€‰åˆ—è¡¨ç”¨äºæ¨¡ç³ŠåŒ¹é…
                candidate_names = []
                for hit in data['hits']['hits']:
                    candidate_name = hit['metadata'].get('name', {}).get('value', '')
                    if not candidate_name:
                        continue

                    # è½¬æ¢åå­—æ ¼å¼ï¼šä»"å§“, å"æ”¹ä¸º"å å§“"
                    if ',' in candidate_name:
                        last_name, first_name = candidate_name.split(',', 1)
                        formatted_name = f"{first_name.strip()} {last_name.strip()}"
                    else:
                        formatted_name = candidate_name

                    normalized_candidate = normalize_name(formatted_name)
                    candidate_names.append((formatted_name, normalized_candidate, hit))

                # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°æœ€æ¥è¿‘çš„ä½œè€…
                best_match = None
                best_score = 0
                for candidate_name, normalized_candidate, hit_data in candidate_names:
                    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
                    score = difflib.SequenceMatcher(
                        None, normalized_query, normalized_candidate
                    ).ratio()

                    # æ›´æ–°æœ€ä½³åŒ¹é…
                    if score > best_score:
                        best_score = score
                        best_match = (candidate_name, hit_data)

                # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è¶³å¤Ÿç›¸ä¼¼çš„åŒ¹é…
                if best_match and best_score > 0.7:  # 70%ç›¸ä¼¼åº¦é˜ˆå€¼
                    match_name, hit_data = best_match
                    recid = hit_data['id']
                    print(f"   âœ… æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: {author_name} â‰ˆ {match_name} (ç›¸ä¼¼åº¦: {best_score:.2f})")
                    return match_name, f"https://inspirehep.net/authors/{recid}"
                else:
                    print(f"   âš ï¸ æ²¡æœ‰è¶³å¤Ÿç›¸ä¼¼çš„åŒ¹é… (æœ€é«˜ç›¸ä¼¼åº¦: {best_score:.2f})")
            else:
                print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä½œè€… {author_name} çš„INSPIREè®°å½•")
        else:
            print(f"   âŒ INSPIRE API é”™è¯¯: HTTP {response.status_code}")
    except Exception as e:
        print(f"   âŒ é€šè¿‡ä½œè€…åæŸ¥æ‰¾æ—¶å‡ºé”™: {str(e)}")

    # æ‰¾ä¸åˆ°
    print(f"   âŒ æ— æ³•æ‰¾åˆ° {author_name} çš„INSPIREé“¾æ¥")

    # æ·»åŠ å»¶è¿Ÿä»¥é¿å…é¢‘ç¹è¯·æ±‚INSPIRE API
    time.sleep(0.3)

    return author_name, None
```

## time_period

è¿™ä¸ªæ˜¯ç”¨æ¥è®¡ç®—æ­¤æ—¶æ­¤åˆ»åº”å½“è·å–å“ªä¸ªæ—¶é—´æ®µçš„è®ºæ–‡

```python
import pytz
from datetime import datetime, timedelta, timezone

import pytz
from datetime import datetime, timedelta, time, timezone


def get_arxiv_submission_period():
    """æ ¹æ®arXivæäº¤æ—¶é—´è¡¨ç¡®å®šå½“å‰åº”è¯¥æŸ¥è¯¢çš„æ—¶é—´æ®µ"""
    # ç¾å›½ä¸œéƒ¨æ—¶åŒº
    eastern = pytz.timezone('US/Eastern')

    # å½“å‰æ—¶é—´ï¼ˆUTCï¼‰è½¬æ¢ä¸ºä¸œéƒ¨æ—¶é—´
    now_utc = datetime.now(timezone.utc)
    now_et = now_utc.astimezone(eastern)

    # è·å–å½“å‰æ˜ŸæœŸå‡ ï¼ˆ0=å‘¨ä¸€ï¼Œ1=å‘¨äºŒï¼Œ...ï¼Œ6=å‘¨æ—¥ï¼‰å’Œå½“å‰æ—¶é—´
    weekday = now_et.weekday()
    current_time = now_et.time()

    # åˆ¤æ–­æ˜¯å¦æ˜¯å‘¨æœ«ä¸”20:00å‰
    is_weekend = False
    if weekday in [5, 6] and current_time < time(20, 0):
        is_weekend = True
        # è®¡ç®—æœ¬å‘¨äº”çš„æ—¥æœŸ
        days_to_friday = (4 - weekday) % 7
        this_friday = now_et - timedelta(days=days_to_friday)

        # è®¾ç½®æ—¶é—´æ®µä¸ºä¸Šå‘¨äº”14:00è‡³æœ¬å‘¨äº”14:00
        start_date = (this_friday - timedelta(days=7)).replace(
            hour=14, minute=0, second=0, microsecond=0
        )
        end_date = this_friday.replace(
            hour=14, minute=0, second=0, microsecond=0
        )
        description = "Friday 14:00 â€“ Friday 14:00 (one week)"
        return start_date, end_date, description, is_weekend

    # éå‘¨æœ«æˆ–å‘¨æœ«20:00åçš„æ­£å¸¸é€»è¾‘
    # æ‰¾å‡ºæœ€è¿‘çš„æœ‰æ•ˆå…¬å¸ƒæ—¶é—´ç‚¹ï¼ˆ20:00 ETï¼‰
    announcement_time = None
    for days_back in range(7):  # æœ€å¤šå›æº¯7å¤©
        candidate_date = now_et - timedelta(days=days_back)
        candidate_weekday = candidate_date.weekday()

        # åªè€ƒè™‘æœ‰æ•ˆå…¬å¸ƒæ—¥ï¼ˆå‘¨ä¸€ã€äºŒã€ä¸‰ã€å››ã€æ—¥ï¼‰
        if candidate_weekday not in [0, 1, 2, 3, 6]:
            continue

        # æ„å»ºå€™é€‰å…¬å¸ƒæ—¶é—´ç‚¹ï¼ˆå½“å¤©20:00 ETï¼‰
        candidate_time = candidate_date.replace(
            hour=20, minute=0, second=0, microsecond=0
        )

        # æ‰¾åˆ°æœ€è¿‘ä¸€ä¸ªå·²å‘ç”Ÿçš„å…¬å¸ƒæ—¶é—´ç‚¹
        if candidate_time <= now_et:
            announcement_time = candidate_time
            break

    # æ ¹æ®å…¬å¸ƒæ—¶é—´ç‚¹ç¡®å®šå¯¹åº”çš„æäº¤æ—¶é—´æ®µ
    if announcement_time is None:
        # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼Œä¸ºå®‰å…¨èµ·è§ä½¿ç”¨é»˜è®¤å€¼
        start_date = now_et - timedelta(days=7)
        end_date = now_et
        description = "Fallback: Last 7 days"
    else:
        ann_weekday = announcement_time.weekday()

        # å‘¨ä¸€å…¬å¸ƒï¼šå‘¨äº”14:00è‡³å‘¨ä¸€14:00
        if ann_weekday == 0:  # Monday
            start_date = (announcement_time - timedelta(days=3)).replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            end_date = announcement_time.replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            description = "Friday 14:00 â€“ Monday 14:00"

        # å‘¨äºŒå…¬å¸ƒï¼šå‘¨ä¸€14:00è‡³å‘¨äºŒ14:00
        elif ann_weekday == 1:  # Tuesday
            start_date = (announcement_time - timedelta(days=1)).replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            end_date = announcement_time.replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            description = "Monday 14:00 â€“ Tuesday 14:00"

        # å‘¨ä¸‰å…¬å¸ƒï¼šå‘¨äºŒ14:00è‡³å‘¨ä¸‰14:00
        elif ann_weekday == 2:  # Wednesday
            start_date = (announcement_time - timedelta(days=1)).replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            end_date = announcement_time.replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            description = "Tuesday 14:00 â€“ Wednesday 14:00"

        # å‘¨å››å…¬å¸ƒï¼šå‘¨ä¸‰14:00è‡³å‘¨å››14:00
        elif ann_weekday == 3:  # Thursday
            start_date = (announcement_time - timedelta(days=1)).replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            end_date = announcement_time.replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            description = "Wednesday 14:00 â€“ Thursday 14:00"

        # å‘¨æ—¥å…¬å¸ƒï¼šå‘¨å››14:00è‡³å‘¨äº”14:00
        elif ann_weekday == 6:  # Sunday
            start_date = (announcement_time - timedelta(days=3)).replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            end_date = (announcement_time - timedelta(days=2)).replace(
                hour=14, minute=0, second=0, microsecond=0
            )
            description = "Thursday 14:00 â€“ Friday 14:00"

    return start_date, end_date, description, is_weekend
```

## arxiv_cats

è¿™ä¸ªæ˜¯arxivåˆ†åŒºçš„å­—å…¸æ‰€åœ¨ä½ç½®
```python
# è·å–æœ‰æ•ˆçš„arXivåˆ†åŒºåˆ—è¡¨
def get_all_arxiv_categories():
    """è·å–arXivå…¨éƒ¨æœ‰æ•ˆåˆ†ç±»ï¼ˆåŒ…å«ä¸€çº§ä¸»åˆ†ç±»å’ŒäºŒçº§å­åˆ†ç±»ï¼‰"""
    return [
        # å¤©ä½“ç‰©ç†å­¦ (astro-ph)
        "astro-ph.GA",  # é“¶æ²³ç³»å¤©ä½“ç‰©ç†å­¦
        "astro-ph.CO",  # å®‡å®™å­¦å’Œæš—ç‰©è´¨
        "astro-ph.EP",  # åœ°çƒå’Œè¡Œæ˜Ÿå¤©ä½“ç‰©ç†å­¦
        "astro-ph.HE",  # é«˜èƒ½å¤©ä½“ç‰©ç†
        "astro-ph.IM",  # ä»ªå™¨å’Œæ–¹æ³•
        "astro-ph.SR",  # å¤ªé˜³å’Œæ’æ˜Ÿå¤©ä½“ç‰©ç†å­¦

        # å‡èšæ€ç‰©ç† (cond-mat)
        "cond-mat.dis-nn",  # æ— åºç³»ç»Ÿå’Œç¥ç»ç½‘ç»œ
        "cond-mat.mes-hall",  # ä»‹è§‚ç³»ç»Ÿå’Œé‡å­éœå°”æ•ˆåº”
        "cond-mat.mtrl-sci",  # ææ–™ç§‘å­¦
        "cond-mat.other",  # å…¶ä»–å‡èšæ€ç‰©ç†
        "cond-mat.quant-gas",  # é‡å­æ°”ä½“
        "cond-mat.soft",  # è½¯å‡èšæ€ç‰©è´¨
        "cond-mat.stat-mech",  # ç»Ÿè®¡åŠ›å­¦
        "cond-mat.str-el",  # å¼ºå…³è”ç”µå­ç³»ç»Ÿ
        "cond-mat.supr-con",  # è¶…å¯¼

        # è®¡ç®—æœºç§‘å­¦ (cs)
        "cs.AI",  # äººå·¥æ™ºèƒ½
        "cs.CL",  # è®¡ç®—è¯­è¨€å­¦
        "cs.CC",  # è®¡ç®—å¤æ‚æ€§
        "cs.CE",  # è®¡ç®—å·¥ç¨‹ã€é‡‘èå’Œç§‘å­¦
        "cs.CG",  # è®¡ç®—å‡ ä½•
        "cs.GT",  # è®¡ç®—æœºç§‘å­¦ä¸åšå¼ˆè®º
        "cs.CV",  # è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«
        "cs.CY",  # è®¡ç®—æœºä¸ç¤¾ä¼š
        "cs.CR",  # å¯†ç å­¦ä¸å®‰å…¨
        "cs.DS",  # æ•°æ®ç»“æ„å’Œç®—æ³•
        "cs.DB",  # æ•°æ®åº“
        "cs.DL",  # æ•°å­—å›¾ä¹¦é¦†
        "cs.DM",  # ç¦»æ•£æ•°å­¦
        "cs.DC",  # åˆ†å¸ƒå¼ã€å¹¶è¡Œå’Œé›†ç¾¤è®¡ç®—
        "cs.ET",  # æ–°å…´æŠ€æœ¯
        "cs.FL",  # å½¢å¼è¯­è¨€ä¸è‡ªåŠ¨æœº
        "cs.GL",  # é€šç”¨æ–‡çŒ®
        "cs.GR",  # å›¾å½¢å­¦
        "cs.AR",  # ç¡¬ä»¶æ¶æ„
        "cs.HC",  # äººæœºäº¤äº’
        "cs.IR",  # ä¿¡æ¯æ£€ç´¢
        "cs.IT",  # ä¿¡æ¯è®º
        "cs.LO",  # è®¡ç®—é€»è¾‘
        "cs.LG",  # æœºå™¨å­¦ä¹ 
        "cs.MS",  # æ•°å­¦è½¯ä»¶
        "cs.MA",  # å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
        "cs.MM",  # å¤šåª’ä½“
        "cs.NI",  # ç½‘ç»œä¸äº’è”ç½‘
        "cs.NE",  # ç¥ç»ä¸æ¼”åŒ–è®¡ç®—
        "cs.NA",  # æ•°å€¼åˆ†æ
        "cs.OS",  # æ“ä½œç³»ç»Ÿ
        "cs.OH",  # å…¶ä»–è®¡ç®—æœºç§‘å­¦
        "cs.PF",  # æ€§èƒ½åˆ†æ
        "cs.PL",  # ç¼–ç¨‹è¯­è¨€
        "cs.RO",  # æœºå™¨äººå­¦
        "cs.SI",  # ç¤¾äº¤ä¸ä¿¡æ¯ç½‘ç»œ
        "cs.SE",  # è½¯ä»¶å·¥ç¨‹
        "cs.SD",  # å£°éŸ³ä¸éŸ³ä¹è®¡ç®—
        "cs.SC",  # ç¬¦å·è®¡ç®—
        "cs.SY",  # ç³»ç»Ÿä¸æ§åˆ¶

        # ç»æµå­¦ (econ)
        "econ.EM",  # è®¡é‡ç»æµå­¦
        "econ.GN",  # é€šç”¨ç»æµå­¦
        "econ.TH",  # ç»æµç†è®º

        # ç”µæ°”å·¥ç¨‹ä¸ç³»ç»Ÿç§‘å­¦ (eess)
        "eess.AS",  # éŸ³é¢‘ä¸è¯­éŸ³å¤„ç†
        "eess.IV",  # å›¾åƒä¸è§†é¢‘å¤„ç†
        "eess.SP",  # ä¿¡å·å¤„ç†
        "eess.SY",  # ç³»ç»Ÿä¸æ§åˆ¶

        # å¹¿ä¹‰ç›¸å¯¹è®ºä¸é‡å­å®‡å®™å­¦ (gr-qc) - æ— å­åˆ†ç±»
        "gr-qc",

        # é«˜èƒ½ç‰©ç†-å®éªŒ (hep-ex) - æ— å­åˆ†ç±»
        "hep-ex",

        # é«˜èƒ½ç‰©ç†-æ ¼ç‚¹ (hep-lat) - æ— å­åˆ†ç±»
        "hep-lat",

        # é«˜èƒ½ç‰©ç†-ç°è±¡å­¦ (hep-ph) - æ— å­åˆ†ç±»
        "hep-ph",

        # é«˜èƒ½ç‰©ç†-ç†è®º (hep-th) - æ— å­åˆ†ç±»
        "hep-th",

        # æ•°å­¦ (math)
        "math.AG",  # ä»£æ•°å‡ ä½•
        "math.AT",  # ä»£æ•°æ‹“æ‰‘
        "math.AP",  # åˆ†æåå¾®åˆ†æ–¹ç¨‹
        "math.CT",  # èŒƒç•´è®º
        "math.CA",  # ç»å…¸åˆ†æå’Œå¸¸å¾®åˆ†æ–¹ç¨‹
        "math.CO",  # ç»„åˆæ•°å­¦
        "math.AC",  # äº¤æ¢ä»£æ•°
        "math.CV",  # å¤å˜é‡
        "math.DG",  # å¾®åˆ†å‡ ä½•
        "math.DS",  # åŠ¨åŠ›ç³»ç»Ÿ
        "math.FA",  # æ³›å‡½åˆ†æ
        "math.GM",  # æ™®é€šæ•°å­¦
        "math.GN",  # ä¸€èˆ¬æ‹“æ‰‘
        "math.GT",  # å‡ ä½•æ‹“æ‰‘
        "math.GR",  # ç¾¤è®º
        "math.HO",  # æ•°å­¦å²å’Œæ¦‚è¿°
        "math.IT",  # ä¿¡æ¯è®º
        "math.KT",  # K-ç†è®º
        "math.LO",  # é€»è¾‘
        "math.MP",  # æ•°å­¦ç‰©ç†
        "math.MG",  # åº¦é‡å‡ ä½•
        "math.NT",  # æ•°è®º
        "math.NA",  # æ•°å€¼åˆ†æ
        "math.OA",  # ç®—å­ä»£æ•°
        "math.OC",  # ä¼˜åŒ–ä¸æ§åˆ¶
        "math.PR",  # æ¦‚ç‡
        "math.QA",  # é‡å­ä»£æ•°
        "math.RT",  # è¡¨ç¤ºè®º
        "math.RA",  # ç¯ä¸ä»£æ•°
        "math.SP",  # è°±ç†è®º
        "math.ST",  # ç»Ÿè®¡å­¦ç†è®º
        "math.SG",  # è¾›å‡ ä½•

        # æ•°å­¦ç‰©ç† (math-ph) - æ— å­åˆ†ç±»
        "math-ph",

        # éçº¿æ€§ç§‘å­¦ (nlin)
        "nlin.AO",  # é€‚åº”æ€§å’Œè‡ªç»„ç»‡ç³»ç»Ÿ
        "nlin.CG",  # ç»†èƒè‡ªåŠ¨æœºå’Œæ™¶æ ¼æ°”ä½“
        "nlin.CD",  # æ··æ²ŒåŠ¨åŠ›å­¦
        "nlin.SI",  # å¯ç§¯ç³»ç»Ÿ
        "nlin.PS",  # æ¨¡å¼å½¢æˆå’Œå­¤å­

        # æ ¸å®éªŒ (nucl-ex) - æ— å­åˆ†ç±»
        "nucl-ex",

        # æ ¸ç†è®º (nucl-th) - æ— å­åˆ†ç±»
        "nucl-th",

        # ç‰©ç†å­¦ (physics)
        "physics.acc-ph",  # åŠ é€Ÿå™¨ç‰©ç†
        "physics.app-ph",  # åº”ç”¨ç‰©ç†
        "physics.ao-ph",  # å¤§æ°”å’Œæµ·æ´‹ç‰©ç†
        "physics.atm-clus",  # åŸå­å’Œå›¢ç°‡ç‰©ç†
        "physics.atom-ph",  # åŸå­ç‰©ç†
        "physics.bio-ph",  # ç”Ÿç‰©ç‰©ç†
        "physics.chem-ph",  # åŒ–å­¦ç‰©ç†
        "physics.class-ph",  # ç»å…¸ç‰©ç†
        "physics.comp-ph",  # è®¡ç®—ç‰©ç†
        "physics.data-an",  # æ•°æ®åˆ†æã€ç»Ÿè®¡å’Œæ¦‚ç‡
        "physics.ed-ph",  # ç‰©ç†æ•™è‚²
        "physics.flu-dyn",  # æµä½“åŠ¨åŠ›å­¦
        "physics.gen-ph",  # æ™®é€šç‰©ç†
        "physics.geo-ph",  # åœ°çƒç‰©ç†
        "physics.hist-ph",  # ç‰©ç†å²
        "physics.ins-det",  # ä»ªå™¨å’Œæ¢æµ‹å™¨
        "physics.med-ph",  # åŒ»å­¦ç‰©ç†
        "physics.optics",  # å…‰å­¦
        "physics.plasm-ph",  # ç­‰ç¦»å­ä½“ç‰©ç†
        "physics.pop-ph",  # å¤§ä¼—ç‰©ç†
        "physics.soc-ph",  # ç‰©ç†ä¸ç¤¾ä¼š
        "physics.space-ph",  # ç©ºé—´ç‰©ç†

        # å®šé‡ç”Ÿç‰©å­¦ (q-bio)
        "q-bio.BM",  # ç”Ÿç‰©åˆ†å­å­¦
        "q-bio.CB",  # ç»†èƒè¡Œä¸º
        "q-bio.GN",  # åŸºå› ç»„å­¦
        "q-bio.MN",  # åˆ†å­ç½‘ç»œ
        "q-bio.NC",  # ç¥ç»å…ƒä¸è®¤çŸ¥
        "q-bio.OT",  # å…¶ä»–å®šé‡ç”Ÿç‰©å­¦
        "q-bio.PE",  # ç§ç¾¤å’Œè¿›åŒ–
        "q-bio.QM",  # å®šé‡æ–¹æ³•
        "q-bio.SC",  # äºšç»†èƒè¿‡ç¨‹
        "q-bio.TO",  # ç»„ç»‡ä¸å™¨å®˜

        # å®šé‡é‡‘èå­¦ (q-fin)
        "q-fin.CP",  # è®¡ç®—é‡‘è
        "q-fin.EC",  # ç»æµå­¦ï¼ˆç†è®ºï¼‰
        "q-fin.GN",  # é€šç”¨é‡‘è
        "q-fin.MF",  # æ•°å­¦é‡‘è
        "q-fin.PM",  # æŠ•èµ„ç»„åˆç®¡ç†
        "q-fin.PR",  # å®šä»·è¯åˆ¸
        "q-fin.RM",  # é£é™©ç®¡ç†
        "q-fin.ST",  # ç»Ÿè®¡é‡‘è
        "q-fin.TR",  # äº¤æ˜“ä¸å¸‚åœºå¾®è§‚ç»“æ„

        # é‡å­ç‰©ç† (quant-ph) - æ— å­åˆ†ç±»
        "quant-ph",

        # ç»Ÿè®¡å­¦ (stat)
        "stat.AP",  # åº”ç”¨ç»Ÿè®¡
        "stat.CO",  # è®¡ç®—ç»Ÿè®¡
        "stat.ML",  # æœºå™¨å­¦ä¹ ç»Ÿè®¡
        "stat.ME",  # æ–¹æ³•è®º
        "stat.OT",  # å…¶ä»–ç»Ÿè®¡
        "stat.TH"  # ç»Ÿè®¡ç†è®º
    ]


def primary_categories():
    """è·å–arXivå…¨éƒ¨æœ‰æ•ˆçš„ä¸€çº§åˆ†ç±»åˆ—è¡¨ï¼ˆä¸»åˆ†ç±»ï¼‰"""
    return [
        # ç‰©ç†ç±»
        "astro-ph",  # å¤©ä½“ç‰©ç†å­¦
        "cond-mat",  # å‡èšæ€ç‰©ç†
        "gr-qc",  # å¹¿ä¹‰ç›¸å¯¹è®ºä¸é‡å­å®‡å®™å­¦
        "hep-ex",  # é«˜èƒ½ç‰©ç†-å®éªŒ
        "hep-lat",  # é«˜èƒ½ç‰©ç†-æ ¼ç‚¹
        "hep-ph",  # é«˜èƒ½ç‰©ç†-ç°è±¡å­¦
        "hep-th",  # é«˜èƒ½ç‰©ç†-ç†è®º
        "nucl-ex",  # æ ¸å®éªŒ
        "nucl-th",  # æ ¸ç†è®º
        "physics",  # ç‰©ç†å­¦ï¼ˆç»¼åˆï¼‰
        "quant-ph",  # é‡å­ç‰©ç†

        # æ•°å­¦ç±»
        "math",  # æ•°å­¦ï¼ˆç»¼åˆï¼‰
        "math-ph",  # æ•°å­¦ç‰©ç†

        # è®¡ç®—æœºç§‘å­¦ç±»
        "cs",  # è®¡ç®—æœºç§‘å­¦ï¼ˆç»¼åˆï¼‰

        # äº¤å‰å­¦ç§‘ç±»
        "nlin",  # éçº¿æ€§ç§‘å­¦
        "q-bio",  # å®šé‡ç”Ÿç‰©å­¦
        "q-fin",  # å®šé‡é‡‘èå­¦

        # å·¥ç¨‹ç±»
        "eess",  # ç”µæ°”å·¥ç¨‹ä¸ç³»ç»Ÿç§‘å­¦

        # ç¤¾ä¼šç§‘å­¦ç±»
        "econ",  # ç»æµå­¦
        "stat"  # ç»Ÿè®¡å­¦
    ]
```

# To Do List

- [ ] å¯¹äºä¹‹å‰å·²ç»æäº¤è¿‡æ—§ç‰ˆæœ¬ç°åœ¨æäº¤çš„æ˜¯æ›´æ–°ç‰ˆæœ¬çš„æ–‡çŒ®é¢å¤–æ ‡å‡ºï¼Œå¹¶ä¸”ç»™å‡ºç¬¬ä¸€ç‰ˆçš„submitæ—¶é—´ä»¥åŠæ–°ç‰ˆç›¸æ¯”äºæ—§ç‰ˆçš„å˜åŒ– 
- [ ] å‘Šè¯‰ç”¨æˆ·ä¸‹æ¬¡æ˜¯ä½•æ—¶æ›´æ–°æ–‡çŒ®
- [ ] è¿›ä¸€æ­¥è§„èŒƒåŒ–mdæ–‡ä»¶å‘½å
- [ ] æœ‰äº›æ•°å­¦æ–‡çŒ®ä¼šå‡ºç°ç±»ä¼¼`05A05`ï¼Œ`05E05`è¿™æ ·çš„ç»†åˆ†å·ï¼Œéœ€è¦åˆ å»

# Bug

ç›®å‰æ²¡å‘ç°